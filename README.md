
# Отчет по домашнему заданию: Диффузионные модели
Данное задание посвящено изучению **диффузионных моделей** для генерации данных, включая изображений и 2D-датасетов. Диффузионные модели являются современным подходом к генеративному обучению: они обучаются поэтапно шумить данные и затем восстанавливать их, что позволяет создавать новые реалистичные объекты.

В рамках работы рассматриваются следующие аспекты:

1. Прямой и обратный процесс диффузии (DDPM).
2. Classifier-free guidance для условной генерации.
3. Ускоренные методы семплинга для повышения скорости генерации.

Эксперименты проводились на 2D-датасете **SwissRoll** и изображениях **MNIST**.

---

## Диффузионные модели

### Прямой и обратный процесс диффузии

Диффузионная модель обучается в два этапа:

1. **Прямой процесс (forward diffusion)**
   На каждом шаге данные постепенно зашумляются с помощью гауссовского шума. С течением времени информация о исходных данных теряется, и на последнем шаге получается почти чистый шум. Этот процесс задаётся вероятностной моделью и позволяет формализовать распределение данных на разных уровнях шума.

2. **Обратный процесс (reverse diffusion)**
   После обучения модель учится «очищать» шум и восстанавливать исходные данные. На каждом шаге обратного процесса модель предсказывает шум и корректирует текущее состояние, двигаясь от чистого шума к реальным данным. Этот процесс позволяет генеративно создавать новые объекты.

Эксперименты на SwissRoll показали постепенное «всплывание» структуры данных при обратном процессе. Для MNIST визуализация прямого процесса демонстрирует, как изображения цифр постепенно становятся неразличимыми и переходят в шум.

---

### Classifier-free guidance

Classifier-free guidance позволяет управлять генерацией данных без явного использования отдельного классификатора. Модель обучается как на условных данных (например, с меткой цифры), так и на условии «пусто» (unconditional). При генерации можно масштабировать влияние условной информации с помощью параметра **guidance scale**.

Эксперименты показали:

* Малые значения guidance scale → генерация ближе к «среднему» распределению, менее ярко выраженные классы.
* Большие значения → цифры более чёткие и хорошо соответствуют условию, но при слишком большом scale возможны артефакты.

---

### Ускоренный семплинг

Классический обратный процесс диффузии требует большого числа шагов, что делает генерацию медленной. **Ускоренные методы** позволяют сократить количество этих шагов, сохраняя качество изображений.

Принцип работы:

* Модель предсказывает шум на нескольких шагах сразу или использует корректировку предыдущих предсказаний.
* Это позволяет уменьшить число итераций обратного процесса и ускорить генерацию.

Такие методы особенно полезны при работе с большими датасетами или при необходимости генерации большого числа изображений за короткое время.

---

## Эксперименты

### SwissRoll

1. Реализован прямой и обратный процесс диффузии.
2. Обучен базовый DDPM.
3. Проверена генерация с использованием classifier-free guidance для разных значений guidance scale.

Результаты показывают, что модель способна постепенно восстанавливать структуру данных и управлять генерацией с помощью guidance.

### MNIST

1. Визуализирован прямой процесс диффузии для примеров цифр.
2. Обучена диффузионная модель для генерации новых изображений цифр.
3. Проведено сравнение unconditional vs conditional генерации в одном коде.

Эксперименты показали:

* Conditional генерация с classifier-free guidance даёт чёткие изображения нужной цифры.
* Unconditional генерация создаёт разнообразные, но менее специфичные цифры.
* Ускоренный семплинг позволяет создавать изображения почти с тем же качеством, но в 2–5 раз быстрее.

---

## Заключение

В ходе работы было изучено и реализовано:

* Прямой и обратный процессы диффузии (DDPM).
* Classifier-free guidance для условной генерации.
* Ускоренные методы семплинга.

Эксперименты на SwissRoll и MNIST подтвердили эффективность диффузионных моделей: они способны качественно генерировать данные и позволяют управлять процессом генерации. Ускоренные методы делают применение моделей практичным даже на больших датасетах.
